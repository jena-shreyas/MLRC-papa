{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5a2omcHjOzM",
        "outputId": "2bae2ef5-8f9f-43db-a6a0-a630002e8801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ğŸ“¦ Installing...\n",
            "ğŸ“Œ Adjusting configuration...\n",
            "ğŸ©¹ Patching environment...\n",
            "â² Done in 0:00:17\n",
            "ğŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "conda create --name env python=3.8 -y\n",
        "source activate env\n",
        "conda install pytorch -c pytorch-lts -c nvidia\n",
        "\n",
        "python -m pip install -U pip\n",
        "pip install --upgrade setuptools\n",
        "pip install transformers==4.18.0\n",
        "\n",
        "pip install datasets accelerate scipy scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLtrMTS-jfnF",
        "outputId": "4107d0e1-f786-4152-9a07-bc91c829221e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 22.9.0\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.8\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
            "    setuptools-65.6.3          |     pyhd8ed1ab_0         619 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         761 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge None\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu None\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4 None\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.12.7-ha878542_0 None\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.39-hcc3a1bd_1 None\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 None\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19 None\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19 None\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0 None\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0 None\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000 None\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4 None\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1 None\n",
            "  openssl            conda-forge/linux-64::openssl-3.0.7-h0b41bf4_1 None\n",
            "  pip                conda-forge/noarch::pip-22.3.1-pyhd8ed1ab_0 None\n",
            "  python             conda-forge/linux-64::python-3.8.15-h4a9ceb5_0_cpython None\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0 None\n",
            "  setuptools         conda-forge/noarch::setuptools-65.6.3-pyhd8ed1ab_0 None\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0 None\n",
            "  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0 None\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00,  6.52it/s]                \n",
            "setuptools-65.6.3    | 619 KB    | : 100% 1.0/1 [00:00<00:00,  6.04it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 22.9.0\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/env\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       2_kmp_llvm           6 KB  conda-forge\n",
            "    blas-2.106                 |              mkl          12 KB  conda-forge\n",
            "    cudatoolkit-11.1.74        |       h6bb024c_0        1.19 GB  nvidia\n",
            "    libblas-3.9.0              |            6_mkl          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |            6_mkl          11 KB  conda-forge\n",
            "    libgfortran-ng-12.2.0      |      h69a702a_19          22 KB  conda-forge\n",
            "    libgfortran5-12.2.0        |      h337968e_19         1.8 MB  conda-forge\n",
            "    liblapack-3.9.0            |            6_mkl          11 KB  conda-forge\n",
            "    liblapacke-3.9.0           |            6_mkl          11 KB  conda-forge\n",
            "    libuv-1.44.2               |       h166bdaf_0         1.0 MB  conda-forge\n",
            "    llvm-openmp-15.0.6         |       he0ac6c6_0         3.3 MB  conda-forge\n",
            "    mkl-2020.4                 |     h726a3e6_304       215.6 MB  conda-forge\n",
            "    ninja-1.11.0               |       h924138e_0         2.8 MB  conda-forge\n",
            "    numpy-1.24.1               |   py38hab0fcb9_0         6.3 MB  conda-forge\n",
            "    pytorch-1.8.2              |py3.8_cuda11.1_cudnn8.0.5_0        1.27 GB  pytorch-lts\n",
            "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.68 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               conda-forge/linux-64::blas-2.106-mkl None\n",
            "  cudatoolkit        nvidia/linux-64::cudatoolkit-11.1.74-h6bb024c_0 None\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-6_mkl None\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-6_mkl None\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19 None\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19 None\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-6_mkl None\n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-6_mkl None\n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-12.2.0-h46fd767_19 None\n",
            "  libuv              conda-forge/linux-64::libuv-1.44.2-h166bdaf_0 None\n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.6-he0ac6c6_0 None\n",
            "  mkl                conda-forge/linux-64::mkl-2020.4-h726a3e6_304 None\n",
            "  ninja              conda-forge/linux-64::ninja-1.11.0-h924138e_0 None\n",
            "  numpy              conda-forge/linux-64::numpy-1.24.1-py38hab0fcb9_0 None\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.8-3_cp38 None\n",
            "  pytorch            pytorch-lts/linux-64::pytorch-1.8.2-py3.8_cuda11.1_cudnn8.0.5_0 None\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0 None\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-2_kmp_llvm None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cudatoolkit-11.1.74  | 1.19 GB   | : 100% 1.0/1 [02:43<00:00, 163.70s/it] \n",
            "libblas-3.9.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 12.72it/s]\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [00:40<00:00, 40.55s/it]               \n",
            "ninja-1.11.0         | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.98it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 12.69it/s]\n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 23.02it/s]\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 13.75it/s]\n",
            "blas-2.106           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 15.53it/s]\n",
            "liblapacke-3.9.0     | 11 KB     | : 100% 1.0/1 [00:00<00:00, 14.80it/s]\n",
            "libuv-1.44.2         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  4.55it/s]\n",
            "numpy-1.24.1         | 6.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.42it/s]               \n",
            "libgfortran-ng-12.2. | 22 KB     | : 100% 1.0/1 [00:00<00:00, 15.70it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 28.24it/s]\n",
            "libgfortran5-12.2.0  | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.83it/s]\n",
            "pytorch-1.8.2        | 1.27 GB   | : 100% 1.0/1 [03:30<00:00, 210.13s/it]\n",
            "llvm-openmp-15.0.6   | 3.3 MB    | : 100% 1.0/1 [00:00<00:00,  7.07it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Retrieving notices: ...working... done\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/envs/env/lib/python3.8/site-packages (22.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/env/lib/python3.8/site-packages (65.6.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.27\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/envs/env/lib/python3.8/site-packages (from transformers==4.18.0) (1.24.1)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/envs/env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.4.0)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting click\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=ba8f085b6ff67d0d5282f42ffc7847192cdd8f369f1b773fc4632f5178d17d42\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/a3/ff/01dc060d7fc51176b3ce7cf1561466a12e658164b594747547\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, urllib3, tqdm, six, regex, pyyaml, packaging, joblib, idna, filelock, click, charset-normalizer, certifi, sacremoses, requests, huggingface-hub, transformers\n",
            "Successfully installed certifi-2022.12.7 charset-normalizer-2.1.1 click-8.1.3 filelock-3.9.0 huggingface-hub-0.11.1 idna-3.4 joblib-1.2.0 packaging-23.0 pyyaml-6.0 regex-2022.10.31 requests-2.28.1 sacremoses-0.0.53 six-1.16.0 tokenizers-0.12.1 tqdm-4.64.1 transformers-4.18.0 urllib3-1.26.14\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=6.0.0\n",
            "  Downloading pyarrow-10.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.0/36.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/envs/env/lib/python3.8/site-packages (from datasets) (0.11.1)\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/envs/env/lib/python3.8/site-packages (from datasets) (6.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/envs/env/lib/python3.8/site-packages (from datasets) (1.24.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/envs/env/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/envs/env/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/env/lib/python3.8/site-packages (from datasets) (23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/envs/env/lib/python3.8/site-packages (from accelerate) (1.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/envs/env/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/envs/env/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m625.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/envs/env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/envs/env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/envs/env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pytz, xxhash, threadpoolctl, scipy, python-dateutil, pyarrow, psutil, multidict, fsspec, frozenlist, dill, attrs, async-timeout, yarl, scikit-learn, responses, pandas, multiprocess, aiosignal, accelerate, aiohttp, datasets\n",
            "Successfully installed accelerate-0.15.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 attrs-22.2.0 datasets-2.8.0 dill-0.3.6 frozenlist-1.3.3 fsspec-2022.11.0 multidict-6.0.4 multiprocess-0.70.14 pandas-1.5.2 psutil-5.9.4 pyarrow-10.0.1 python-dateutil-2.8.2 pytz-2022.7 responses-0.18.0 scikit-learn-1.2.0 scipy-1.10.0 threadpoolctl-3.1.0 xxhash-3.2.0 yarl-1.8.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate env\n",
        "git clone https://github.com/schwartz-lab-NLP/papa.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8HUnX1pniek",
        "outputId": "a1a03d70-7683-43be-8581-4c72b338c946"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'papa'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 120 (delta 40), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (120/120), 143.52 KiB | 3.88 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls papa/transformers/src/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKNu3TnbBfiN",
        "outputId": "22195920-22f5-4aa1-eb37-2d54eee5153c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modeling_utils.py  models  papa_modules.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy local transformers content to installed transformers location\n",
        "!cp -R papa/transformers/src/transformers/* /usr/local/envs/env/lib/python3.8/site-packages/transformers/"
      ],
      "metadata": {
        "id": "WOu5NBYqnDS_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/envs/env/lib/python3.8/site-packages/transformers/ | grep papa_modules.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb_aHFP51FDk",
        "outputId": "8714a882-8953-47f1-f383-89038ecfc020"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "papa_modules.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install huggingface_hub\n",
        "# !huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Ysku8zocGS",
        "outputId": "ffee7c66-c6e6-4d22-99d8-3ed495309920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.8/site-packages (0.11.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/site-packages (from huggingface_hub) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from huggingface_hub) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface_hub) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from huggingface_hub) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->huggingface_hub) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->huggingface_hub) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->huggingface_hub) (1.26.13)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n",
            "    \n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid.\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate env\n",
        "pip install sentencepiece   # For deberta tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6LMGVWYhN7v",
        "outputId": "7cfc9341-58b9-421d-c41c-68306f6651a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL NAMES :\n",
        "\n",
        "`DeBERTa` : microsoft/deberta-base , microsoft/deberta-large\n",
        "\n",
        "`BERT` : bert-base-uncased , bert-large-uncased\n",
        "\n",
        "`RoBERTa` : roberta-base , roberta-large"
      ],
      "metadata": {
        "id": "hoo_VI1duJa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`numpy`>=1.20.3 but <= 1.24.0 would be needed for the `DeBERTa` code to run."
      ],
      "metadata": {
        "id": "M1yl55w7wh5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate env\n",
        "pip uninstall numpy -y\n",
        "pip install numpy==1.20.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS59kenpvykN",
        "outputId": "f3501b18-7749-4628-ff73-7f0c5417fad4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.24.1\n",
            "Uninstalling numpy-1.24.1:\n",
            "  Successfully uninstalled numpy-1.24.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.20.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate env\n",
        "cd papa/transformers/papa_scripts\n",
        "\n",
        "MODEL=microsoft/deberta-base\n",
        "TASK=sst2\n",
        "\n",
        "python3 run_papa_glue_avgs_creator.py --model_name_or_path ${MODEL}  --task_name ${TASK}  --max_length 64    --per_device_train_batch_size 8   --output_dir ../../constant-matrices/ --cache_dir ../../cache/ --use_papa_preprocess true  --pad_to_max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMBMB-MZn_iz",
        "outputId": "450a9a8d-de63-44a4-d073-14062d07a556"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01/11/2023 14:11:39 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Mixed precision type: no\n",
            "\n",
            "Downloading and preparing dataset glue/sst2 to /content/papa/transformers/papa_scripts/../../cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n",
            "Downloading data: 100% 7.44M/7.44M [00:00<00:00, 8.54MB/s]\n",
            "Dataset glue downloaded and prepared to /content/papa/transformers/papa_scripts/../../cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 574.20it/s]\n",
            "loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"sst2\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/microsoft/deberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/ce0ac094af27cf80bbf403595a6d47f1fc632981bf1d4c5bf69968568cbea410.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n",
            "loading file https://huggingface.co/microsoft/deberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/05056f257c8d2b63ad16fd26f847c9ab9ee34e33cdfad926e132be824b237869.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/microsoft/deberta-base/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/deberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/deberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/deberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c2bc27a1c7529c177696ff76b1e74cba8667be14e202359f20f9114e407f43e2.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n",
            "loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "https://huggingface.co/microsoft/deberta-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /content/papa/cache/tmp209ozzf7\n",
            "Downloading: 100% 533M/533M [00:08<00:00, 67.4MB/s]\n",
            "storing https://huggingface.co/microsoft/deberta-base/resolve/main/pytorch_model.bin in cache at ../../cache/dde0725208c11536042f6f416c538792d44a2d57d1ae399bbd1bc5867e02c465.0a3ec262cb3d4f634c72ce55f2766bb88771e6499b2512830e2e63bf19dbf97a\n",
            "creating metadata file for ../../cache/dde0725208c11536042f6f416c538792d44a2d57d1ae399bbd1bc5867e02c465.0a3ec262cb3d4f634c72ce55f2766bb88771e6499b2512830e2e63bf19dbf97a\n",
            "loading weights file https://huggingface.co/microsoft/deberta-base/resolve/main/pytorch_model.bin from cache at ../../cache/dde0725208c11536042f6f416c538792d44a2d57d1ae399bbd1bc5867e02c465.0a3ec262cb3d4f634c72ce55f2766bb88771e6499b2512830e2e63bf19dbf97a\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on dataset: 100% 68/68 [00:07<00:00,  9.19ba/s]\n",
            "Running tokenizer on dataset: 100% 1/1 [00:01<00:00,  1.98s/ba]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:04<00:00,  2.07s/ba]\n",
            "01/11/2023 14:12:12 - INFO - __main__ - Sample 63685 of the training set: {'input_ids': [1, 560, 10, 25609, 31368, 14, 34, 117, 9927, 1437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'labels': 0}.\n",
            "01/11/2023 14:12:12 - INFO - __main__ - Sample 34844 of the training set: {'input_ids': [1, 24770, 13367, 6269, 1437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'labels': 1}.\n",
            "01/11/2023 14:12:12 - INFO - __main__ - Sample 52005 of the training set: {'input_ids': [1, 4321, 9378, 2156, 55, 3722, 1437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'labels': 1}.\n",
            "/usr/local/envs/env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "run_papa_glue_avgs_creator.py:452: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", args.task_name)\n",
            "01/11/2023 14:12:16 - INFO - __main__ - ***** Running training *****\n",
            "01/11/2023 14:12:16 - INFO - __main__ -   Num examples = 67349\n",
            "01/11/2023 14:12:16 - INFO - __main__ -   Num Epochs = 3\n",
            "01/11/2023 14:12:16 - INFO - __main__ -   Instantaneous batch size per device = 8\n",
            "01/11/2023 14:12:16 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "01/11/2023 14:12:16 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "01/11/2023 14:12:16 - INFO - __main__ -   Total optimization steps = 25257\n",
            "  0% 0/25257 [05:42<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate env\n",
        "cd papa/transformers/papa_scripts\n",
        "\n",
        "MODEL=microsoft/deberta-base\n",
        "TASK=sst2\n",
        "\n",
        "python3 run_papa_glue.py --model_name_or_path ${MODEL} --task_name ${TASK} --do_eval --max_seq_length 64 --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --output_dir ../../sorted-heads/ --cache_dir ../../cache/  --do_train --num_train_epochs 15.0 --learning_rate 2e-5 --lr_scheduler_type constant --disable_tqdm true --evaluation_strategy epoch --save_strategy no --use_papa_preprocess --use_freeze_extract_pooler true --static_heads_dir ../../constant-matrices/  --save_total_limit 0 --sort_calculating True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Dmx5bsl1o0",
        "outputId": "5f20b6b7-e8a1-463e-ccdd-8a6b922ddf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01/11/2023 14:18:02 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "01/11/2023 14:18:02 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=True,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.EPOCH,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=../../sorted-heads/runs/Jan11_14-18-02_25146437496d,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.CONSTANT,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=15.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=../../sorted-heads/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=../../sorted-heads/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.NO,\n",
            "save_total_limit=0,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "01/11/2023 14:18:03 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "01/11/2023 14:18:03 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "01/11/2023 14:18:03 - INFO - datasets.info - Loading Dataset info from ../../cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "01/11/2023 14:18:03 - WARNING - datasets.builder - Found cached dataset glue (/content/papa/transformers/papa_scripts/../../cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "01/11/2023 14:18:03 - INFO - datasets.info - Loading Dataset info from /content/papa/transformers/papa_scripts/../../cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "100% 3/3 [00:00<00:00, 695.88it/s]\n",
            "[INFO|hub.py:583] 2023-01-11 14:18:03,948 >> https://huggingface.co/microsoft/deberta-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /content/papa/cache/tmprcib13y4\n",
            "Downloading: 100% 474/474 [00:00<00:00, 373kB/s]\n",
            "[INFO|hub.py:587] 2023-01-11 14:18:04,101 >> storing https://huggingface.co/microsoft/deberta-base/resolve/main/config.json in cache at ../../cache/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "[INFO|hub.py:595] 2023-01-11 14:18:04,101 >> creating metadata file for ../../cache/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "[INFO|configuration_utils.py:654] 2023-01-11 14:18:04,101 >> loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at ../../cache/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "[INFO|configuration_utils.py:690] 2023-01-11 14:18:04,103 >> Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"sst2\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2023-01-11 14:18:04,259 >> https://huggingface.co/microsoft/deberta-base/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /content/papa/cache/tmplsar1t2p\n",
            "Downloading: 100% 52.0/52.0 [00:00<00:00, 38.9kB/s]\n",
            "[INFO|hub.py:587] 2023-01-11 14:18:04,423 >> storing https://huggingface.co/microsoft/deberta-base/resolve/main/tokenizer_config.json in cache at ../../cache/c2bc27a1c7529c177696ff76b1e74cba8667be14e202359f20f9114e407f43e2.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n",
            "[INFO|hub.py:595] 2023-01-11 14:18:04,423 >> creating metadata file for ../../cache/c2bc27a1c7529c177696ff76b1e74cba8667be14e202359f20f9114e407f43e2.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n",
            "[INFO|configuration_utils.py:654] 2023-01-11 14:18:04,584 >> loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at ../../cache/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "[INFO|configuration_utils.py:690] 2023-01-11 14:18:04,585 >> Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2023-01-11 14:18:04,895 >> https://huggingface.co/microsoft/deberta-base/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /content/papa/cache/tmp9i0quz6s\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 5.27MB/s]\n",
            "[INFO|hub.py:587] 2023-01-11 14:18:05,240 >> storing https://huggingface.co/microsoft/deberta-base/resolve/main/vocab.json in cache at ../../cache/ce0ac094af27cf80bbf403595a6d47f1fc632981bf1d4c5bf69968568cbea410.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n",
            "[INFO|hub.py:595] 2023-01-11 14:18:05,240 >> creating metadata file for ../../cache/ce0ac094af27cf80bbf403595a6d47f1fc632981bf1d4c5bf69968568cbea410.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n",
            "[INFO|hub.py:583] 2023-01-11 14:18:05,402 >> https://huggingface.co/microsoft/deberta-base/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /content/papa/cache/tmpspwwyu8j\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 3.13MB/s]\n",
            "[INFO|hub.py:587] 2023-01-11 14:18:05,720 >> storing https://huggingface.co/microsoft/deberta-base/resolve/main/merges.txt in cache at ../../cache/05056f257c8d2b63ad16fd26f847c9ab9ee34e33cdfad926e132be824b237869.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|hub.py:595] 2023-01-11 14:18:05,720 >> creating metadata file for ../../cache/05056f257c8d2b63ad16fd26f847c9ab9ee34e33cdfad926e132be824b237869.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1778] 2023-01-11 14:18:06,325 >> loading file https://huggingface.co/microsoft/deberta-base/resolve/main/vocab.json from cache at ../../cache/ce0ac094af27cf80bbf403595a6d47f1fc632981bf1d4c5bf69968568cbea410.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n",
            "[INFO|tokenization_utils_base.py:1778] 2023-01-11 14:18:06,325 >> loading file https://huggingface.co/microsoft/deberta-base/resolve/main/merges.txt from cache at ../../cache/05056f257c8d2b63ad16fd26f847c9ab9ee34e33cdfad926e132be824b237869.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1778] 2023-01-11 14:18:06,325 >> loading file https://huggingface.co/microsoft/deberta-base/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2023-01-11 14:18:06,325 >> loading file https://huggingface.co/microsoft/deberta-base/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2023-01-11 14:18:06,325 >> loading file https://huggingface.co/microsoft/deberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2023-01-11 14:18:06,325 >> loading file https://huggingface.co/microsoft/deberta-base/resolve/main/tokenizer_config.json from cache at ../../cache/c2bc27a1c7529c177696ff76b1e74cba8667be14e202359f20f9114e407f43e2.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n",
            "[INFO|configuration_utils.py:654] 2023-01-11 14:18:06,483 >> loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "[INFO|configuration_utils.py:690] 2023-01-11 14:18:06,484 >> Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:654] 2023-01-11 14:18:06,715 >> loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at ../../cache/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
            "[INFO|configuration_utils.py:690] 2023-01-11 14:18:06,715 >> Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"max_seq_length\": 512,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"sort_calculating\": null,\n",
            "  \"static_heads\": null,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"use_freeze_extract_pooler\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1430] 2023-01-11 14:18:07,026 >> loading weights file https://huggingface.co/microsoft/deberta-base/resolve/main/pytorch_model.bin from cache at ../../cache/dde0725208c11536042f6f416c538792d44a2d57d1ae399bbd1bc5867e02c465.0a3ec262cb3d4f634c72ce55f2766bb88771e6499b2512830e2e63bf19dbf97a\n",
            "[WARNING|modeling_utils.py:1688] 2023-01-11 14:18:08,800 >> Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:1699] 2023-01-11 14:18:08,800 >> Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['deberta.encoder.layer.11.attention.self.static_heads_content', 'deberta.encoder.layer.9.attention.self.lambdas', 'deberta.encoder.layer.1.attention.self.lambdas', 'classifier.weight', 'deberta.encoder.layer.3.attention.self.static_heads_content', 'deberta.encoder.layer.10.attention.self.lambdas', 'deberta.encoder.layer.7.attention.self.lambdas', 'deberta.encoder.layer.5.attention.self.lambdas', 'pooler.weights_per_layer', 'deberta.encoder.layer.11.attention.self.lambdas', 'deberta.encoder.layer.8.attention.self.lambdas', 'deberta.encoder.layer.9.attention.self.static_heads_content', 'deberta.encoder.layer.2.attention.self.static_heads_content', 'deberta.encoder.layer.5.attention.self.static_heads_content', 'deberta.encoder.layer.7.attention.self.static_heads_content', 'deberta.encoder.layer.6.attention.self.lambdas', 'deberta.encoder.layer.0.attention.self.lambdas', 'deberta.encoder.layer.3.attention.self.lambdas', 'pooler.dense_across_layers.bias', 'deberta.encoder.layer.2.attention.self.lambdas', 'classifier.bias', 'deberta.encoder.layer.8.attention.self.static_heads_content', 'deberta.encoder.layer.4.attention.self.lambdas', 'deberta.encoder.layer.0.attention.self.static_heads_content', 'deberta.encoder.layer.1.attention.self.static_heads_content', 'deberta.encoder.layer.6.attention.self.static_heads_content', 'deberta.encoder.layer.4.attention.self.static_heads_content', 'pooler.dense_across_layers.weight', 'deberta.encoder.layer.10.attention.self.static_heads_content']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Not frozen param:  deberta.encoder.layer.0.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.1.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.2.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.3.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.4.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.5.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.6.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.7.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.8.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.9.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.10.attention.self.lambdas\n",
            "Not frozen param:  deberta.encoder.layer.11.attention.self.lambdas\n",
            "Not frozen param:  pooler.weights_per_layer\n",
            "Not frozen param:  pooler.dense_across_layers.weight\n",
            "Not frozen param:  pooler.dense_across_layers.bias\n",
            "Not frozen param:  classifier.weight\n",
            "Not frozen param:  classifier.bias\n",
            "Running tokenizer on dataset:   0% 0/68 [00:00<?, ?ba/s]01/11/2023 14:18:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/papa/cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-5001d1fdb1291c67.arrow\n",
            "Running tokenizer on dataset: 100% 68/68 [00:07<00:00,  9.05ba/s]\n",
            "Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s]01/11/2023 14:18:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/papa/cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-53fe5f6fc7c5afba.arrow\n",
            "Running tokenizer on dataset: 100% 1/1 [00:02<00:00,  2.07s/ba]\n",
            "Running tokenizer on dataset:   0% 0/2 [00:00<?, ?ba/s]01/11/2023 14:18:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /content/papa/cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-480aaf9c2dc01c51.arrow\n",
            "Running tokenizer on dataset: 100% 2/2 [00:04<00:00,  2.08s/ba]\n",
            "01/11/2023 14:18:22 - INFO - __main__ - Sample 14592 of the training set: {'sentence': 'a great movie ', 'label': 1, 'idx': 14592, 'input_ids': [1, 102, 372, 1569, 1437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'old_input_ids': [1, 102, 372, 1569, 1437, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'old_attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "01/11/2023 14:18:22 - INFO - __main__ - Sample 3278 of the training set: {'sentence': 'entertaining , if somewhat standardized , action ', 'label': 1, 'idx': 3278, 'input_ids': [1, 1342, 2399, 8173, 2156, 114, 5568, 28631, 2156, 814, 1437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'old_input_ids': [1, 1342, 2399, 8173, 2156, 114, 5568, 28631, 2156, 814, 1437, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'old_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "01/11/2023 14:18:22 - INFO - __main__ - Sample 36048 of the training set: {'sentence': 'even when there are lulls , the emotions seem authentic , ', 'label': 1, 'idx': 36048, 'input_ids': [1, 12963, 77, 89, 32, 29620, 29, 2156, 5, 8597, 2045, 12757, 2156, 1437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'old_input_ids': [1, 12963, 77, 89, 32, 29620, 29, 2156, 5, 8597, 2045, 12757, 2156, 1437, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'old_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "run_papa_glue.py:567: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", data_args.task_name)\n",
            "[INFO|trainer.py:566] 2023-01-11 14:18:25,950 >> The following columns in the training set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/envs/env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1290] 2023-01-11 14:18:25,959 >> ***** Running training *****\n",
            "[INFO|trainer.py:1291] 2023-01-11 14:18:25,959 >>   Num examples = 67349\n",
            "[INFO|trainer.py:1292] 2023-01-11 14:18:25,959 >>   Num Epochs = 15\n",
            "[INFO|trainer.py:1293] 2023-01-11 14:18:25,959 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1294] 2023-01-11 14:18:25,959 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1295] 2023-01-11 14:18:25,959 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1296] 2023-01-11 14:18:25,959 >>   Total optimization steps = 63150\n",
            "{'loss': 0.5232, 'learning_rate': 2e-05, 'epoch': 0.12}\n",
            "{'loss': 0.4024, 'learning_rate': 2e-05, 'epoch': 0.24}\n",
            "{'loss': 0.3903, 'learning_rate': 2e-05, 'epoch': 0.36}\n",
            "{'loss': 0.3629, 'learning_rate': 2e-05, 'epoch': 0.48}\n",
            "{'loss': 0.3513, 'learning_rate': 2e-05, 'epoch': 0.59}\n",
            "{'loss': 0.3316, 'learning_rate': 2e-05, 'epoch': 0.71}\n",
            "{'loss': 0.3455, 'learning_rate': 2e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3414, 'learning_rate': 2e-05, 'epoch': 0.95}\n",
            "[INFO|trainer.py:566] 2023-01-11 14:29:11,645 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 14:29:11,647 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 14:29:11,647 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 14:29:11,647 >>   Batch size = 16\n",
            "01/11/2023 14:29:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.3336818516254425, 'eval_accuracy': 0.8646788990825688, 'eval_runtime': 4.0302, 'eval_samples_per_second': 216.364, 'eval_steps_per_second': 13.647, 'epoch': 1.0}\n",
            "{'loss': 0.3189, 'learning_rate': 2e-05, 'epoch': 1.07}\n",
            "{'loss': 0.3355, 'learning_rate': 2e-05, 'epoch': 1.19}\n",
            "{'loss': 0.3173, 'learning_rate': 2e-05, 'epoch': 1.31}\n",
            "{'loss': 0.3198, 'learning_rate': 2e-05, 'epoch': 1.43}\n",
            "{'loss': 0.3235, 'learning_rate': 2e-05, 'epoch': 1.54}\n",
            "{'loss': 0.3115, 'learning_rate': 2e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3099, 'learning_rate': 2e-05, 'epoch': 1.78}\n",
            "{'loss': 0.3034, 'learning_rate': 2e-05, 'epoch': 1.9}\n",
            "[INFO|trainer.py:566] 2023-01-11 14:39:56,839 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 14:39:56,841 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 14:39:56,841 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 14:39:56,841 >>   Batch size = 16\n",
            "01/11/2023 14:40:00 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.3192158341407776, 'eval_accuracy': 0.8646788990825688, 'eval_runtime': 3.9896, 'eval_samples_per_second': 218.569, 'eval_steps_per_second': 13.786, 'epoch': 2.0}\n",
            "{'loss': 0.3003, 'learning_rate': 2e-05, 'epoch': 2.02}\n",
            "{'loss': 0.3137, 'learning_rate': 2e-05, 'epoch': 2.14}\n",
            "{'loss': 0.3003, 'learning_rate': 2e-05, 'epoch': 2.26}\n",
            "{'loss': 0.3005, 'learning_rate': 2e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2976, 'learning_rate': 2e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2933, 'learning_rate': 2e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2968, 'learning_rate': 2e-05, 'epoch': 2.73}\n",
            "{'loss': 0.3041, 'learning_rate': 2e-05, 'epoch': 2.85}\n",
            "{'loss': 0.2948, 'learning_rate': 2e-05, 'epoch': 2.97}\n",
            "[INFO|trainer.py:566] 2023-01-11 14:50:44,727 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 14:50:44,729 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 14:50:44,729 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 14:50:44,729 >>   Batch size = 16\n",
            "01/11/2023 14:50:48 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.28764277696609497, 'eval_accuracy': 0.8899082568807339, 'eval_runtime': 4.0265, 'eval_samples_per_second': 216.563, 'eval_steps_per_second': 13.659, 'epoch': 3.0}\n",
            "{'loss': 0.2823, 'learning_rate': 2e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2834, 'learning_rate': 2e-05, 'epoch': 3.21}\n",
            "{'loss': 0.2838, 'learning_rate': 2e-05, 'epoch': 3.33}\n",
            "{'loss': 0.3008, 'learning_rate': 2e-05, 'epoch': 3.44}\n",
            "{'loss': 0.2779, 'learning_rate': 2e-05, 'epoch': 3.56}\n",
            "{'loss': 0.3007, 'learning_rate': 2e-05, 'epoch': 3.68}\n",
            "{'loss': 0.2879, 'learning_rate': 2e-05, 'epoch': 3.8}\n",
            "{'loss': 0.2892, 'learning_rate': 2e-05, 'epoch': 3.92}\n",
            "[INFO|trainer.py:566] 2023-01-11 15:01:33,239 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 15:01:33,241 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 15:01:33,242 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 15:01:33,242 >>   Batch size = 16\n",
            "01/11/2023 15:01:37 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.3215791881084442, 'eval_accuracy': 0.8612385321100917, 'eval_runtime': 4.0161, 'eval_samples_per_second': 217.127, 'eval_steps_per_second': 13.695, 'epoch': 4.0}\n",
            "{'loss': 0.2816, 'learning_rate': 2e-05, 'epoch': 4.04}\n",
            "{'loss': 0.2753, 'learning_rate': 2e-05, 'epoch': 4.16}\n",
            "{'loss': 0.2836, 'learning_rate': 2e-05, 'epoch': 4.28}\n",
            "{'loss': 0.2813, 'learning_rate': 2e-05, 'epoch': 4.39}\n",
            "{'loss': 0.2684, 'learning_rate': 2e-05, 'epoch': 4.51}\n",
            "{'loss': 0.2754, 'learning_rate': 2e-05, 'epoch': 4.63}\n",
            "{'loss': 0.2884, 'learning_rate': 2e-05, 'epoch': 4.75}\n",
            "{'loss': 0.2713, 'learning_rate': 2e-05, 'epoch': 4.87}\n",
            "{'loss': 0.2884, 'learning_rate': 2e-05, 'epoch': 4.99}\n",
            "[INFO|trainer.py:566] 2023-01-11 15:12:19,473 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 15:12:19,475 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 15:12:19,475 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 15:12:19,475 >>   Batch size = 16\n",
            "01/11/2023 15:12:23 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.2900824248790741, 'eval_accuracy': 0.8864678899082569, 'eval_runtime': 4.005, 'eval_samples_per_second': 217.727, 'eval_steps_per_second': 13.733, 'epoch': 5.0}\n",
            "{'loss': 0.2769, 'learning_rate': 2e-05, 'epoch': 5.11}\n",
            "{'loss': 0.2693, 'learning_rate': 2e-05, 'epoch': 5.23}\n",
            "{'loss': 0.2704, 'learning_rate': 2e-05, 'epoch': 5.34}\n",
            "{'loss': 0.2643, 'learning_rate': 2e-05, 'epoch': 5.46}\n",
            "{'loss': 0.2651, 'learning_rate': 2e-05, 'epoch': 5.58}\n",
            "{'loss': 0.2738, 'learning_rate': 2e-05, 'epoch': 5.7}\n",
            "{'loss': 0.2762, 'learning_rate': 2e-05, 'epoch': 5.82}\n",
            "{'loss': 0.2573, 'learning_rate': 2e-05, 'epoch': 5.94}\n",
            "[INFO|trainer.py:566] 2023-01-11 15:23:04,993 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 15:23:04,995 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 15:23:04,995 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 15:23:04,995 >>   Batch size = 16\n",
            "01/11/2023 15:23:09 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.2840827703475952, 'eval_accuracy': 0.8899082568807339, 'eval_runtime': 4.0101, 'eval_samples_per_second': 217.453, 'eval_steps_per_second': 13.715, 'epoch': 6.0}\n",
            "{'loss': 0.2706, 'learning_rate': 2e-05, 'epoch': 6.06}\n",
            "{'loss': 0.2663, 'learning_rate': 2e-05, 'epoch': 6.18}\n",
            "{'loss': 0.268, 'learning_rate': 2e-05, 'epoch': 6.29}\n",
            "{'loss': 0.2632, 'learning_rate': 2e-05, 'epoch': 6.41}\n",
            "{'loss': 0.2513, 'learning_rate': 2e-05, 'epoch': 6.53}\n",
            "{'loss': 0.2571, 'learning_rate': 2e-05, 'epoch': 6.65}\n",
            "{'loss': 0.2685, 'learning_rate': 2e-05, 'epoch': 6.77}\n",
            "{'loss': 0.2726, 'learning_rate': 2e-05, 'epoch': 6.89}\n",
            "[INFO|trainer.py:566] 2023-01-11 15:33:49,880 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 15:33:49,882 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 15:33:49,882 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 15:33:49,882 >>   Batch size = 16\n",
            "01/11/2023 15:33:53 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.28793931007385254, 'eval_accuracy': 0.8910550458715596, 'eval_runtime': 4.0327, 'eval_samples_per_second': 216.231, 'eval_steps_per_second': 13.638, 'epoch': 7.0}\n",
            "{'loss': 0.2611, 'learning_rate': 2e-05, 'epoch': 7.01}\n",
            "{'loss': 0.2653, 'learning_rate': 2e-05, 'epoch': 7.13}\n",
            "{'loss': 0.27, 'learning_rate': 2e-05, 'epoch': 7.24}\n",
            "{'loss': 0.2575, 'learning_rate': 2e-05, 'epoch': 7.36}\n",
            "{'loss': 0.27, 'learning_rate': 2e-05, 'epoch': 7.48}\n",
            "{'loss': 0.2445, 'learning_rate': 2e-05, 'epoch': 7.6}\n",
            "{'loss': 0.2544, 'learning_rate': 2e-05, 'epoch': 7.72}\n",
            "{'loss': 0.251, 'learning_rate': 2e-05, 'epoch': 7.84}\n",
            "{'loss': 0.2541, 'learning_rate': 2e-05, 'epoch': 7.96}\n",
            "[INFO|trainer.py:566] 2023-01-11 15:44:38,052 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 15:44:38,055 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 15:44:38,055 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 15:44:38,055 >>   Batch size = 16\n",
            "01/11/2023 15:44:42 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.2946053743362427, 'eval_accuracy': 0.8967889908256881, 'eval_runtime': 4.0206, 'eval_samples_per_second': 216.885, 'eval_steps_per_second': 13.68, 'epoch': 8.0}\n",
            "{'loss': 0.2568, 'learning_rate': 2e-05, 'epoch': 8.08}\n",
            "{'loss': 0.2527, 'learning_rate': 2e-05, 'epoch': 8.19}\n",
            "{'loss': 0.2681, 'learning_rate': 2e-05, 'epoch': 8.31}\n",
            "{'loss': 0.2451, 'learning_rate': 2e-05, 'epoch': 8.43}\n",
            "{'loss': 0.2516, 'learning_rate': 2e-05, 'epoch': 8.55}\n",
            "{'loss': 0.254, 'learning_rate': 2e-05, 'epoch': 8.67}\n",
            "{'loss': 0.2498, 'learning_rate': 2e-05, 'epoch': 8.79}\n",
            "{'loss': 0.2477, 'learning_rate': 2e-05, 'epoch': 8.91}\n",
            "[INFO|trainer.py:566] 2023-01-11 15:55:25,633 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 15:55:25,635 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 15:55:25,635 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 15:55:25,635 >>   Batch size = 16\n",
            "01/11/2023 15:55:29 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.2851182520389557, 'eval_accuracy': 0.8956422018348624, 'eval_runtime': 4.021, 'eval_samples_per_second': 216.861, 'eval_steps_per_second': 13.678, 'epoch': 9.0}\n",
            "{'loss': 0.2491, 'learning_rate': 2e-05, 'epoch': 9.03}\n",
            "{'loss': 0.2391, 'learning_rate': 2e-05, 'epoch': 9.14}\n",
            "{'loss': 0.2335, 'learning_rate': 2e-05, 'epoch': 9.26}\n",
            "{'loss': 0.2529, 'learning_rate': 2e-05, 'epoch': 9.38}\n",
            "{'loss': 0.2364, 'learning_rate': 2e-05, 'epoch': 9.5}\n",
            "{'loss': 0.2395, 'learning_rate': 2e-05, 'epoch': 9.62}\n",
            "{'loss': 0.2581, 'learning_rate': 2e-05, 'epoch': 9.74}\n",
            "{'loss': 0.2514, 'learning_rate': 2e-05, 'epoch': 9.86}\n",
            "{'loss': 0.2507, 'learning_rate': 2e-05, 'epoch': 9.98}\n",
            "[INFO|trainer.py:566] 2023-01-11 16:06:11,531 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 16:06:11,533 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 16:06:11,533 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 16:06:11,533 >>   Batch size = 16\n",
            "01/11/2023 16:06:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow\n",
            "{'eval_loss': 0.2957228422164917, 'eval_accuracy': 0.8887614678899083, 'eval_runtime': 4.0007, 'eval_samples_per_second': 217.964, 'eval_steps_per_second': 13.748, 'epoch': 10.0}\n",
            "{'loss': 0.2474, 'learning_rate': 2e-05, 'epoch': 10.1}\n",
            "{'loss': 0.2445, 'learning_rate': 2e-05, 'epoch': 10.21}\n",
            "{'loss': 0.2312, 'learning_rate': 2e-05, 'epoch': 10.33}\n",
            "{'loss': 0.2382, 'learning_rate': 2e-05, 'epoch': 10.45}\n",
            "{'loss': 0.2379, 'learning_rate': 2e-05, 'epoch': 10.57}\n",
            "{'loss': 0.2208, 'learning_rate': 2e-05, 'epoch': 10.69}\n",
            "{'loss': 0.2482, 'learning_rate': 2e-05, 'epoch': 10.81}\n",
            "{'loss': 0.2369, 'learning_rate': 2e-05, 'epoch': 10.93}\n",
            "[INFO|trainer.py:566] 2023-01-11 16:16:56,680 >> The following columns in the evaluation set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: sentence, old_input_ids, old_attention_mask, idx. If sentence, old_input_ids, old_attention_mask, idx are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2023-01-11 16:16:56,683 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2023-01-11 16:16:56,683 >>   Num examples = 872\n",
            "[INFO|trainer.py:2421] 2023-01-11 16:16:56,683 >>   Batch size = 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the following cell for base models (total heads = 12 (heads_per_layer) * 12 (num_layers) = 144)"
      ],
      "metadata": {
        "id": "Z-Pf0VXfoOa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p papa/results/\n",
        "mkdir -p papa/results/0\n",
        "mkdir -p papa/results/72\n",
        "mkdir -p papa/results/126\n",
        "mkdir -p papa/results/135\n",
        "mkdir -p papa/results/144"
      ],
      "metadata": {
        "id": "QME7PRSlUCUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate env\n",
        "cd papa/transformers/papa_scripts\n",
        "\n",
        "MODEL=microsoft/deberta-base\n",
        "TASK=sst2\n",
        "\n",
        "for static_heads_num in 0 72 126 135 144\n",
        " do\n",
        "    python3 run_papa_glue.py --model_name_or_path ${MODEL} --task_name ${TASK} --do_eval --max_seq_length 64 --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --output_dir ../../output/ --overwrite_output_dir --cache_dir ../../cache/ --do_train --num_train_epochs 15.0 --learning_rate 2e-5 --lr_scheduler_type constant --disable_tqdm true --evaluation_strategy epoch --save_strategy no --use_papa_preprocess --grad_for_classifier_only true --use_freeze_extract_pooler true --static_heads_dir ../../constant-matrices/ --static_heads_num ${static_heads_num} --save_total_limit 0 --sorting_heads_dir ../../sorted-heads/\n",
        "    cp ../../output/README.md ../../results/${static_heads_num}/\n",
        " done"
      ],
      "metadata": {
        "id": "JtwYXVWXg5iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the following cell for large models (total heads = 16 (heads_per_layer) * 24 (num_layers) = 384)"
      ],
      "metadata": {
        "id": "5zIGrWPQoSR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "mkdir -p papa/results/\n",
        "mkdir -p papa/results/0\n",
        "mkdir -p papa/results/192\n",
        "mkdir -p papa/results/336\n",
        "mkdir -p papa/results/360\n",
        "mkdir -p papa/results/384"
      ],
      "metadata": {
        "id": "yZoiigSUoXq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate env\n",
        "cd papa/transformers/papa_scripts\n",
        "\n",
        "MODEL=bert-large-uncased\n",
        "TASK=cola\n",
        "\n",
        "for static_heads_num in 0 192 336 360 384\n",
        " do\n",
        "    python3 run_papa_glue.py --model_name_or_path ${MODEL} --task_name ${TASK} --do_eval --max_seq_length 64 --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --output_dir ../../output/ --overwrite_output_dir --cache_dir ../../cache/ --do_train --num_train_epochs 15.0 --learning_rate 2e-5 --lr_scheduler_type constant --disable_tqdm true --evaluation_strategy epoch --save_strategy no --use_papa_preprocess --grad_for_classifier_only true --use_freeze_extract_pooler true --static_heads_dir ../../constant-matrices/ --static_heads_num ${static_heads_num} --save_total_limit 0 --sorting_heads_dir ../../sorted-heads/\n",
        "    cp ../../output/README.md ../../results/${static_heads_num}/\n",
        " done"
      ],
      "metadata": {
        "id": "Y7IaFqovoXYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the outputs "
      ],
      "metadata": {
        "id": "Wr8b2VcuofYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd papa\n",
        "\n",
        "MODEL=deberta-base\n",
        "TASK=sst2\n",
        "\n",
        "zip -r /content/${MODEL}_${TASK}_constant-matrices.zip constant-matrices/\n",
        "zip -r /content/${MODEL}_${TASK}_sorted-heads.zip sorted-heads/\n",
        "zip -r /content/${MODEL}_${TASK}_results.zip results/\n",
        "zip -r /content/${MODEL}_${TASK}_output.zip output/"
      ],
      "metadata": {
        "id": "W5wwnXMl1aW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "MODEL=\"deberta-base\"\n",
        "TASK=\"sst2\"\n",
        "\n",
        "files.download(f\"/content/{MODEL}_{TASK}_constant-matrices.zip\")\n",
        "files.download(f\"/content/{MODEL}_{TASK}_sorted-heads.zip\")\n",
        "files.download(f\"/content/{MODEL}_{TASK}_results.zip\")\n",
        "files.download(f\"/content/{MODEL}_{TASK}_output.zip\")"
      ],
      "metadata": {
        "id": "gm3Nsf2l2nq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear directory before running each new model\n",
        "%rm -rf papa/cache/*\n",
        "%rm -rf papa/constant-matrices/*\n",
        "%rm -rf papa/sorted-heads/*\n",
        "%rm -rf papa/output/*\n",
        "%rm -rf papa/results/*"
      ],
      "metadata": {
        "id": "tD4fgTvIZFj4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "l-U846Odt9NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate env\n",
        "python\n",
        "\n",
        "import torch\n",
        "attention_sums = torch.load('papa/transformers/papa_scripts/outputs/attention_sums.pt')\n",
        "print(f\"Shape of attention_sums : {attention_sums.size()}\")         # (num_layers=12, num_heads=12, )\n",
        "\n",
        "print(attention_sums[0][0].min())\n",
        "# DIMENSIONS :\n",
        "\n",
        "# num_layers = 12\n",
        "# num_heads = 12\n",
        "# num_input_tokens (n) = 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD6Ocg8VwZPv",
        "outputId": "90dd9747-6a82-424c-b9a1-e123c3a98697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of attention_sums : torch.Size([12, 12, 64, 64])\n",
            "tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aJIfQjrPB9l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}